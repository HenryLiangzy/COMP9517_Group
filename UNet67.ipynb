{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1VvxJM6DmmN3WeA93xC4X0gLk_pyzvTKc"},"id":"KsaelWTRANRK","outputId":"2a43bd66-efae-4c2c-8428-710ee09b8c21"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from PIL import Image\n","import keras\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n","from tensorflow.keras.layers import  Dropout, Activation\n","from tensorflow.keras.optimizers import Adam, SGD\n","from keras.layers.advanced_activations import LeakyReLU\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.utils import plot_model\n","import tensorflow as tf\n","import glob\n","import random\n","import cv2\n","from random import shuffle\n","\n","\"\"\"Note that we have two foulders. The first one is `images` which contains the raw images and annotation which contains the masks as a `binary` foulder image.\n","## Dataset Preparation\n","\"\"\"\n","\n","def image_generator(files, batch_size =10 , sz = (256, 256)):\n","  \n","  while True: \n","    \n","    #extract a random batch \n","    batch = np.random.choice(files, size = batch_size)    \n","    \n","    #variables for collecting batches of inputs and outputs \n","    batch_x = []\n","    batch_y = []\n","    \n","    \n","    for f in batch:\n","        \n","        #get the masks. Note that masks are png files \n","        mask = Image.open(f[-9::-1][::-1]+'_fg.png')\n","        mask = np.array(mask.resize(sz))\n","\n","\n","        #preprocess the mask \n","        mask[mask \u003e= 2] = 0 \n","        mask[mask != 0 ] = 1\n","        \n","        batch_y.append(mask)\n","\n","        #preprocess the raw images \n","        raw = Image.open(f)\n","        raw = raw.resize(sz)\n","        raw = np.array(raw)\n","\n","        #check the number of channels because some of the images are RGBA or GRAY\n","        if len(raw.shape) == 2:\n","          raw = np.stack((raw,)*3, axis=-1)\n","\n","        else:\n","          raw = raw[:,:,0:3]\n","\n","        batch_x.append(raw)\n","\n","    #preprocess a batch of images and masks \n","    batch_x = np.array(batch_x)/255.\n","    batch_y = np.array(batch_y)\n","    batch_y = np.expand_dims(batch_y,3)\n","\n","    yield (batch_x, batch_y)\n","\n","all_files=[]\n","for i in os.listdir('/content/drive/My Drive/project/A1'):\n","  if i[-5:]=='b.png':\n","    all_files.append('/content/drive/My Drive/project/A1/'+i)  \n","for i in os.listdir('/content/drive/My Drive/project/A2'):\n","  if i[-5:]=='b.png':\n","    all_files.append('/content/drive/My Drive/project/A2/'+i)\n","\"\"\"   \n","for i in os.listdir('/content/drive/My Drive/leaf1/images/A3'):\n","  if i[-5:]=='b.png':\n","    all_files.append('/content/drive/My Drive/leaf1/images/A3/'+i)   \n","for i in os.listdir('/content/drive/My Drive/leaf1/images/A4'):\n","  if i[-5:]=='b.png':\n","    all_files.append('/content/drive/My Drive/leaf1/images/A4/'+i)\n","\"\"\"\n","\n","batch_size = 10\n","shuffle(all_files)\n","split = int(0.9 * len(all_files))\n","#split into training and testing\n","train_files = all_files[0:split]\n","test_files  = all_files[split:]\n","\n","train_generator = image_generator(train_files, batch_size = batch_size)\n","test_generator  = image_generator(test_files, batch_size = batch_size)\n","\n","x, y= next(train_generator)\n","\n","\"\"\"# IoU metric\n","The intersection over union (IoU) metric is a simple metric used to evaluate the performance of a segmentation algorithm. Given two masks $x_{true}, x_{pred}$ we evaluate \n","$$IoU = \\frac{y_{true} \\cap y_{pred}}{y_{true} \\cup y_{pred}}$$\n","\"\"\"\n","\n","def mean_iou(y_true, y_pred):\n","    yt0 = y_true[:,:,:,0]\n","    yp0 = K.cast(y_pred[:,:,:,0] \u003e 0.5, 'float32')\n","    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n","    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n","    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n","    return iou\n","\n","\"\"\"# Model\"\"\"\n","\n","def unet(sz = (256, 256, 3)):\n","  x = Input(sz)\n","  inputs = x\n","  \n","  #down sampling \n","  f = 8\n","  layers = []\n","  \n","  for i in range(0, 6):\n","    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n","    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n","    layers.append(x)\n","    x = MaxPooling2D() (x)\n","    f = f*2\n","  ff2 = 64 \n","  \n","  #bottleneck \n","  j = len(layers) - 1\n","  x = Conv2D(f, 3, activation='tanh', padding='same') (x)\n","  x = Conv2D(f, 3, activation='tanh', padding='same') (x)\n","  x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n","  x = Concatenate(axis=3)([x, layers[j]])\n","  j = j -1 \n","  \n","  #upsampling \n","  for i in range(0, 5):\n","    ff2 = ff2//2\n","    f = f // 2 \n","    x = Conv2D(f, 3, activation='tanh', padding='same') (x)\n","    x = Conv2D(f, 3, activation='tanh', padding='same') (x)\n","    x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n","    x = Concatenate(axis=3)([x, layers[j]])\n","    j = j -1 \n","    \n","  \n","  #classification \n","  x = Conv2D(f, 3, activation='tanh', padding='same') (x)\n","  x = Conv2D(f, 3, activation='tanh', padding='same') (x)\n","  outputs = Conv2D(1, 1, activation='sigmoid') (x)\n","  \n","  #model creation \n","  model = Model(inputs=[inputs], outputs=[outputs])\n","  model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n","  \n","  return model\n","\n","model = unet()\n","\n","model.summary()\n","\n","\"\"\"# Training\"\"\"\n","\n","train_steps = len(train_files) //batch_size\n","test_steps = len(test_files) //batch_size\n","model.fit(train_generator,epochs = 100,steps_per_epoch=train_steps,validation_data=test_generator,validation_steps=10,verbose=0)\n","\n","model.save_weights('/content/drive/My Drive/project/weights.h5')"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyOn/IuIQ21Dw99jtCM9ARSL","mount_file_id":"15LC0-0qZD48aMTGwz8gmbblqGRwu5-Pa","name":"UNet67.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}